---
autor: Simon Janke
title: Data Analytics Best Practices
type: Ressource
date: 2025-10-12
tags:
  - best-practices
  - tipps
  - qualitÃ¤t
  - workflow
---

# ğŸŒŸ Data Analytics Best Practices

Ein umfassender Leitfaden fÃ¼r professionelle Datenanalyse.

---

## ğŸ¯ 1. Projektplanung & Fragestellung

### âœ… Best Practices

#### Klare Zielsetzung
```
âŒ Schlecht: "Analysiere unsere Kundendaten"
âœ… Gut: "Identifiziere die Top 3 Faktoren, die die Kundenabwanderung 
         im Q3 2025 beeinflusst haben, um Retention-Strategien zu entwickeln"
```

#### SMART-Fragen verwenden
- **S**pezifisch: Genau definiert
- **M**essbar: Quantifizierbar
- **A**ction-oriented: FÃ¼hrt zu Handlungen
- **R**elevant: Wichtig fÃ¼r Business
- **T**ime-bound: Zeitlich begrenzt

#### Stakeholder-Alignment
```
Vor Projektbeginn klÃ¤ren:
âœ“ Was ist das GeschÃ¤ftsproblem?
âœ“ Wer sind die Stakeholder?
âœ“ Was sind die Erfolgskriterien?
âœ“ Welche Daten sind verfÃ¼gbar?
âœ“ Was ist der Zeitrahmen?
âœ“ Wie werden Ergebnisse genutzt?
```

### âš ï¸ HÃ¤ufige Fehler vermeiden

```
âŒ Direkt mit Datenanalyse beginnen ohne Kontext
âŒ LÃ¶sungsorientiert statt problemorientiert denken
âŒ Annahmen nicht dokumentieren
âŒ Stakeholder-Erwartungen nicht managen
```

---

## ğŸ“Š 2. Datensammlung & -vorbereitung

### âœ… Best Practices

#### DatenqualitÃ¤t prÃ¼fen
```python
# Checklist fÃ¼r neue Datenquellen:
âœ“ VollstÃ¤ndigkeit: Sind alle erwarteten Daten vorhanden?
âœ“ Genauigkeit: Sind die Werte korrekt?
âœ“ Konsistenz: Sind Formate einheitlich?
âœ“ AktualitÃ¤t: Sind die Daten aktuell?
âœ“ Relevanz: Sind die Daten fÃ¼r die Fragestellung relevant?
```

#### Datenherkunft dokumentieren
```
FÃ¼r jede Datenquelle festhalten:
- Quelle (z.B. Google Analytics, CRM-System)
- Extraktionsdatum
- Verantwortliche Person
- Bekannte Limitationen
- Transformationen angewendet
```

#### Backups erstellen
```
âœ“ Originaldaten NIEMALS Ã¼berschreiben
âœ“ Versionierung verwenden (data_v1, data_v2)
âœ“ Transformation-Scripts speichern
```

### âš ï¸ HÃ¤ufige Fehler vermeiden

```
âŒ Originaldaten Ã¼berschreiben
âŒ Keine Dokumentation der Bereinigungsschritte
âŒ Bias in der Datensammlung ignorieren
âŒ Stichproben ohne ReprÃ¤sentativitÃ¤t prÃ¼fen
```

---

## ğŸ§¹ 3. Datenbereinigung

### âœ… Best Practices

#### Systematischer Approach
```
1. Ãœberblick verschaffen
   - Datentypen prÃ¼fen
   - Nullwerte identifizieren
   - Duplikate finden
   - Statistiken ansehen

2. Bereinigungsplan erstellen
   - Was wird bereinigt?
   - Wie wird es bereinigt?
   - Warum diese Methode?

3. Schrittweise bereinigen
   - Ein Problem nach dem anderen
   - Jeder Schritt dokumentiert
   - Ergebnisse validieren

4. QualitÃ¤tschecks
   - Vor/Nach-Vergleich
   - Stichproben prÃ¼fen
   - Edge Cases testen
```

#### Fehlende Daten behandeln
```
Strategien je nach Kontext:

âœ“ LÃ¶schen (wenn < 5% fehlen und zufÃ¤llig)
âœ“ Imputation mit Durchschnitt/Median (bei numerisch)
âœ“ Most Frequent Value (bei kategoriell)
âœ“ Als eigene Kategorie "Unknown" (wenn Muster)
âœ“ VorwÃ¤rts-/RÃ¼ckwÃ¤rtsfÃ¼llen (bei Zeitreihen)

âŒ NICHT einfach mit 0 ersetzen (verzerrt Statistiken)
```

#### SQL Best Practices fÃ¼r Cleaning
```sql
-- âœ… Gut: Explizit NULL-Handling
SELECT 
  customer_id,
  COALESCE(email, 'unknown@example.com') AS email,
  COALESCE(country, 'Unknown') AS country
FROM customers;

-- âœ… Gut: Duplikate identifizieren BEVOR lÃ¶schen
SELECT email, COUNT(*) as count
FROM customers
GROUP BY email
HAVING COUNT(*) > 1;

-- âœ… Gut: Trimming und Case-Standardisierung
SELECT 
  TRIM(UPPER(country)) AS country_clean
FROM customers;
```

### âš ï¸ HÃ¤ufige Fehler vermeiden

```
âŒ Fehlende Werte einfach mit 0 ersetzen
âŒ Duplikate blind lÃ¶schen (kÃ¶nnten legitim sein)
âŒ AusreiÃŸer automatisch entfernen (kÃ¶nnten wichtig sein)
âŒ Datentypen nicht konvertieren (z.B. "123" als Text)
```

---

## ğŸ” 4. Explorative Datenanalyse (EDA)

### âœ… Best Practices

#### Start mit den Basics
```
1. Deskriptive Statistiken
   - Mittelwert, Median, Modus
   - Min, Max, Quartile
   - Standardabweichung

2. Verteilungen verstehen
   - Histogramme fÃ¼r numerisch
   - Balkendiagramme fÃ¼r kategoriell
   - Normal verteilt vs. skewed?

3. Beziehungen erkunden
   - Korrelationsmatrix
   - Scatterplots
   - Gruppenvergleiche
```

#### Visualisierung fÃ¼r Exploration
```
âœ“ Mehrere Darstellungen probieren
âœ“ Verschiedene Aggregationslevel
âœ“ Segmentierung nach wichtigen Dimensionen
âœ“ Zeitliche Trends untersuchen
âœ“ Outliers visuell identifizieren
```

#### Hypothesen bilden
```
Nach EDA solltest du haben:
1. Liste interessanter Muster
2. VorlÃ¤ufige Hypothesen
3. Identifizierte Anomalien
4. Fragen fÃ¼r tiefere Analyse
```

### âš ï¸ HÃ¤ufige Fehler vermeiden

```
âŒ Nur Durchschnitte betrachten (Verteilung wichtig!)
âŒ Korrelation als KausalitÃ¤t interpretieren
âŒ Selection Bias nicht berÃ¼cksichtigen
âŒ Zeitliche Effekte ignorieren (SaisonalitÃ¤t)
```

---

## ğŸ“ˆ 5. Datenanalyse & Statistik

### âœ… Best Practices

#### Statistisch korrekt denken
```
âœ“ StichprobengrÃ¶ÃŸe berÃ¼cksichtigen
  - n < 30: Vorsicht mit Durchschnitten
  - n > 1000: Auch kleine Effekte signifikant
  
âœ“ Konfidenzintervalle angeben
  "Conversion Rate ist 2,5% Â± 0,3% (95% CI)"
  Nicht nur: "Conversion Rate ist 2,5%"

âœ“ P-Werte richtig interpretieren
  p < 0.05 bedeutet NICHT "Hypothese ist wahr"
  Es bedeutet: "Unwahrscheinlich durch Zufall"
```

#### A/B-Tests richtig durchfÃ¼hren
```
Vor dem Test:
âœ“ Hypothese klar formulieren
âœ“ Sample Size berechnen
âœ“ Randomisierung sicherstellen
âœ“ Laufzeit festlegen (min. 1 Woche)

WÃ¤hrend des Tests:
âœ“ NICHT vorzeitig stoppen wenn "gut aussieht"
âœ“ Keine Ã„nderungen am Test wÃ¤hrend Laufzeit
âœ“ Externe Faktoren dokumentieren

Nach dem Test:
âœ“ Statistische Signifikanz prÃ¼fen
âœ“ Praktische Signifikanz bewerten
âœ“ Segmentanalyse durchfÃ¼hren
âœ“ Langfristige Effekte monitoren
```

#### Segmentierung sinnvoll nutzen
```
âœ“ Nach sinnvollen Business-Dimensionen:
  - Kundentyp (B2B vs. B2C)
  - Region
  - Produktkategorie
  - Nutzungsverhalten

âœ“ MindestgrÃ¶ÃŸe pro Segment beachten
  - Min. 100-500 Datenpunkte
  - Sonst: Zusammenfassen

âœ“ Simpson's Paradox beachten
  - Gesamttrend vs. Segmenttrends kÃ¶nnen gegensÃ¤tzlich sein
```

### âš ï¸ HÃ¤ufige Fehler vermeiden

```
âŒ Cherry-Picking: Nur positive Ergebnisse zeigen
âŒ P-Hacking: Solange testen bis signifikant
âŒ Multiple Testing ohne Korrektur
âŒ Causation aus Correlation schlieÃŸen
âŒ Survivorship Bias (nur "Ãœberlebende" analysieren)
```

---

## ğŸ’» 6. SQL Best Practices

### âœ… Best Practices

#### Lesbarkeit
```sql
-- âœ… Gut: Ãœbersichtlich formatiert
SELECT 
  c.customer_id,
  c.name,
  COUNT(o.order_id) AS order_count,
  SUM(o.total_amount) AS total_spent
FROM customers c
LEFT JOIN orders o 
  ON c.customer_id = o.customer_id
WHERE o.order_date >= '2025-01-01'
GROUP BY c.customer_id, c.name
HAVING COUNT(o.order_id) > 5
ORDER BY total_spent DESC
LIMIT 100;

-- âŒ Schlecht: Alles in einer Zeile
SELECT c.customer_id,c.name,COUNT(o.order_id),SUM(o.total_amount) FROM customers c LEFT JOIN orders o ON c.customer_id=o.customer_id WHERE o.order_date>='2025-01-01' GROUP BY c.customer_id,c.name HAVING COUNT(o.order_id)>5 ORDER BY 4 DESC LIMIT 100;
```

#### Performance-Optimierung
```sql
-- âœ… Gut: Filter VOR JOIN
SELECT c.name, o.total
FROM (
  SELECT * FROM customers WHERE country = 'Germany'
) c
JOIN orders o ON c.customer_id = o.customer_id;

-- âŒ Langsam: Filter NACH JOIN
SELECT c.name, o.total
FROM customers c
JOIN orders o ON c.customer_id = o.customer_id
WHERE c.country = 'Germany';

-- âœ… Gut: LIMIT in Subqueries
SELECT * 
FROM (
  SELECT * FROM large_table LIMIT 1000
) sub
WHERE condition;

-- âœ… Gut: Indexierte Spalten in WHERE/JOIN verwenden
```

#### CTEs statt Subqueries (fÃ¼r Lesbarkeit)
```sql
-- âœ… Gut: Mit CTE
WITH high_value_customers AS (
  SELECT customer_id
  FROM orders
  GROUP BY customer_id
  HAVING SUM(total) > 10000
),
recent_orders AS (
  SELECT *
  FROM orders
  WHERE order_date >= '2025-01-01'
)
SELECT *
FROM recent_orders ro
JOIN high_value_customers hvc 
  ON ro.customer_id = hvc.customer_id;

-- âŒ Kompliziert: Verschachtelte Subqueries
SELECT *
FROM (SELECT * FROM orders WHERE order_date >= '2025-01-01') ro
JOIN (SELECT customer_id FROM orders GROUP BY customer_id HAVING SUM(total) > 10000) hvc
  ON ro.customer_id = hvc.customer_id;
```

### âš ï¸ HÃ¤ufige Fehler vermeiden

```sql
-- âŒ SELECT * in Production
SELECT * FROM large_table;  -- Langsam, verschwendet Ressourcen

-- âŒ Fehlende WHERE in UPDATE/DELETE
DELETE FROM customers;  -- LÃ¶scht ALLES!

-- âŒ JOIN ohne ON (Cartesian Product)
SELECT * FROM table1, table2;  -- Explosiver Datensatz

-- âŒ Strings mit != NULL vergleichen
WHERE email != NULL  -- Funktioniert nicht!
-- âœ… Richtig:
WHERE email IS NOT NULL
```

---

## ğŸ“Š 7. Visualisierung & Kommunikation

### âœ… Best Practices

#### Chart-Auswahl
```
Ziel                    â†’ Diagrammtyp
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Vergleich               â†’ Balkendiagramm
Zeitverlauf             â†’ Liniendiagramm
Teil-vom-Ganzen         â†’ Kreisdiagramm (max. 5-7 Segmente)
Verteilung              â†’ Histogramm, Boxplot
Beziehung/Korrelation   â†’ Scatterplot
Geografisch             â†’ Karte, Heatmap
Hierarchie              â†’ Treemap, Sunburst
```

#### Design-Prinzipien
```
âœ“ Weniger ist mehr
  - Max. 5-7 Farben pro Visualisierung
  - Fokus auf wichtigste Insights
  - UnnÃ¶tige Dekorationen weglassen

âœ“ Accessibility
  - Farbblindheit berÃ¼cksichtigen
  - Ausreichend Kontrast
  - Achsenbeschriftungen klar

âœ“ Ehrliche Darstellung
  - Y-Achse bei 0 starten (bei Mengen)
  - Keine manipulativen Skalierungen
  - Unsicherheit zeigen (Konfidenzintervalle)

âœ“ Kontext geben
  - Vergleichswerte (Benchmarks, Vorjahr)
  - Titel aussagekrÃ¤ftig
  - Quellen angeben
```

#### Storytelling mit Daten
```
Struktur:
1. Kontext setzen
   "Unser Umsatz ist um 15% gesunken"

2. Warum wichtig?
   "Das entspricht 2Mâ‚¬ Verlust und gefÃ¤hrdet Jahresziele"

3. Was ist passiert?
   "Analyse zeigt: 3 Hauptfaktoren..."
   [Visualisierung]

4. Was bedeutet das?
   "Wenn wir nichts tun, erwarten wir..."

5. Was empfehlen wir?
   "Unsere Top 3 Empfehlungen..."
```

### âš ï¸ HÃ¤ufige Fehler vermeiden

```
âŒ 3D-Diagramme (verzerren Proportionen)
âŒ Zu viele Daten in einem Chart
âŒ IrrefÃ¼hrende Achsen (nicht bei 0)
âŒ Junk Charts (unnÃ¶tige Dekorationen)
âŒ Falsche Charttypen (Kreisdiagramm fÃ¼r Trends)
âŒ Keine Beschriftungen/Legenden
```

---

## ğŸ“ 8. Dokumentation

### âœ… Best Practices

#### Was dokumentieren?
```
1. Projektdokumentation
   - Zielsetzung und Scope
   - Annahmen und Limitationen
   - Methodologie
   - Ergebnisse und Insights
   - Empfehlungen

2. Code-Dokumentation
   - Was macht der Code?
   - Warum diese Methode?
   - Input/Output
   - Dependencies
   - Beispiele

3. Daten-Dokumentation
   - Datenquellen
   - Schema (Tabellen, Spalten)
   - Bereinigungsschritte
   - Transformationen
   - Bekannte Issues
```

#### README-Template
```markdown
# Projekt: Kundenabwanderungsanalyse Q3 2025

## Zielsetzung
Identifiziere HauptgrÃ¼nde fÃ¼r 25% Churn-Anstieg

## Daten
- Quelle: CRM-System (Export 01.10.2025)
- Zeitraum: Jan 2024 - Sep 2025
- Umfang: 50.000 Kunden, 150.000 Transaktionen

## Methodik
1. Datenbereinigung (siehe cleaning_script.sql)
2. RFM-Segmentierung
3. Logistische Regression
4. Feature Importance Analyse

## Wichtigste Erkenntnisse
1. Kunden mit Support-Tickets > 3 churnen 5x hÃ¤ufiger
2. PreiserhÃ¶hung im MÃ¤rz korreliert mit Churn-Spike
3. Onboarding-QualitÃ¤t ist #1 PrÃ¤diktor

## Empfehlungen
1. Proaktive Support-Eskalation bei 3+ Tickets
2. PreiserhÃ¶hungs-Kommunikation verbessern
3. Onboarding-Prozess Ã¼berarbeiten

## Files
- data/: Rohdaten und bereinigt
- scripts/: SQL und Python Scripts
- results/: Outputs und Visualisierungen
- report.pdf: Executive Summary
```

#### Code-Kommentare
```sql
-- âœ… Gut: ErklÃ¤rt WARUM, nicht WAS
-- Verwende LEFT JOIN um auch Kunden ohne Bestellungen zu inkludieren
-- Business-Anforderung: Alle Kunden sollen in Report erscheinen
SELECT c.*, COUNT(o.order_id) AS order_count
FROM customers c
LEFT JOIN orders o ON c.customer_id = o.customer_id
GROUP BY c.customer_id;

-- âŒ Schlecht: Wiederholt nur den Code
-- Left join customers und orders
SELECT c.*, COUNT(o.order_id) AS order_count
FROM customers c
LEFT JOIN orders o ON c.customer_id = o.customer_id
GROUP BY c.customer_id;
```

---

## ğŸ”„ 9. Reproduzierbarkeit & Versionierung

### âœ… Best Practices

#### Git fÃ¼r Versionskontrolle
```bash
# Struktur
project/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/              # Originaldaten (nicht versioniert)
â”‚   â””â”€â”€ processed/        # Bereinigt (nicht versioniert)
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ 01_cleaning.sql
â”‚   â”œâ”€â”€ 02_analysis.sql
â”‚   â””â”€â”€ 03_visualization.py
â”œâ”€â”€ results/
â”‚   â””â”€â”€ report.pdf
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt      # Dependencies
```

#### Reproduzierbare Analysen
```python
# âœ… Gut: Seed fÃ¼r Zufallsgenerierung
import numpy as np
np.random.seed(42)

# âœ… Gut: Dependencies dokumentieren
# requirements.txt
pandas==2.0.0
numpy==1.24.0
scikit-learn==1.3.0

# âœ… Gut: Relative Pfade
import os
data_path = os.path.join(os.getcwd(), 'data', 'raw', 'customers.csv')
```

---

## ğŸš€ 10. Continuous Improvement

### âœ… Best Practices

#### Nach jedem Projekt
```
âœ“ Was lief gut?
âœ“ Was kÃ¶nnte verbessert werden?
âœ“ Welche Tools/Methoden waren effektiv?
âœ“ Was habe ich gelernt?
âœ“ Feedback von Stakeholdern einholen
```

#### Weiterbildung
```
âœ“ Neue Tools/Techniken ausprobieren
âœ“ Best Practices anderer lernen
âœ“ Code Reviews durchfÃ¼hren/erhalten
âœ“ Community teilnehmen (Kaggle, Reddit, etc.)
âœ“ Eigene Projekte fÃ¼r Portfolio
```

---

## ğŸ“š Checkliste: Projekt-Review

Bevor Projekt als "abgeschlossen" markiert wird:

**DatenqualitÃ¤t**
- [ ] Alle Bereinigungsschritte dokumentiert
- [ ] Datenquellen validiert
- [ ] Edge Cases geprÃ¼ft
- [ ] Nullwerte behandelt

**Analyse**
- [ ] Annahmen explizit genannt
- [ ] Statistische Tests korrekt angewendet
- [ ] SensitivitÃ¤tsanalyse durchgefÃ¼hrt
- [ ] Alternative ErklÃ¤rungen geprÃ¼ft

**Visualisierung**
- [ ] Charttypen passend gewÃ¤hlt
- [ ] Achsen korrekt beschriftet
- [ ] Legenden verstÃ¤ndlich
- [ ] Farben accessibility-freundlich

**Kommunikation**
- [ ] Executive Summary vorhanden
- [ ] Kernbotschaft klar
- [ ] Empfehlungen actionable
- [ ] Limitationen transparent

**Dokumentation**
- [ ] README vollstÃ¤ndig
- [ ] Code kommentiert
- [ ] Reproduzierbarkeit gegeben
- [ ] Dependencies dokumentiert

**Stakeholder**
- [ ] Erwartungen erfÃ¼llt
- [ ] Feedback eingeholt
- [ ] Follow-up-Fragen beantwortet
- [ ] NÃ¤chste Schritte definiert

---

*Aktualisiert: Oktober 2025*